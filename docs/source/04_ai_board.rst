.. _04_ai_board:
04 Getting overview with AI on the blackboard
==============================================

.. index:: artificial, intelligence, cluster, HPC, transformers, CUDA, gguf, llama_cpp, neurons

.. image:: AI_board.JPG

The Hugging face platform and the AIs
___________________________
"Hugging Face is a machine learning (ML) and data science platform and community that helps users build, deploy and train machine learning models." Ben Lutkevich on `Tech Target <https://www.techtarget.com/whatis/definition/Hugging-Face>`_. `Hugging face <https://huggingface.co/>`_ is a good place to start, when you want to familiarize yourself with the LLMs. However, in this course you do not need to download them, because we, the instructors have already done some of the work for you. If you want to learn, keep reading!

Ny overskrift
-------------
**A large language model (LLM)** is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks. LLMs are trained on huge sets of data — hence the name "large." LLMs are built on machine learning: specifically, a type of neural network called a transformer model (Cloudflare 2024).


 **Nvidia** is a producer of graphics processing units; GPU. 

**Huggingface**. 

**Open AIs and available AIs** In this project group, we believe open or available LLMs are beneficial for science. This is why we want to teach people how to use them. 

**Transformers** Artificial intelligence models from Huggingface are specific implementations of Transformer architecture. The transformer architecture has made self-supervised learning of neural networks possible, and represents a leap in computer science.

**AI** is a term that is meant to denote what is happening, when a computer do things that require intelligence when done by people (Heaven 2024). In this workshop we are going to work with LLMs: A type of artificial intelligence program.

**CUDA** means Compute Unified Device Architecture. According to Wikipedia is a proprietary parallel computing platform and interface, that allows software to use certain types of graphics processing units (GPUs) (Wikipedia Nov. 12th 2024). It has programming languages C++, Cuda C and libraries for mathemathics like cuBLAS. Cuda is made by the firm Nvidia.

**Cluster**, The Fox is a High performance `computing cluster <https://www.uio.no/english/services/it/research/hpc/fox/>`_ for Educloud research users. A Computing Cluster is a set of connected computers that work so closely together that in many respects they function as a single computer. In this workshop, you will learn how to run an LLM (**Large Language Model**) at the UiO Nvidia Cluster.

.. image:: fox_hpc.png
(UiO it department 2024: dScience – Centre for Computational and Data Science)

**HPC**, A High Performance Computing cluster

**Transformers** A transformer is a learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper "Attention Is All You Need" (Vaswani et.al. 2023).


**The .gguf format** developed by @ggerganov is a quantified AI file format that that stores both tensors and metadata in a single file.

**llama_cpp** is a C++ library that allows us to run quantized models. The cpp format also developed by developed by @ggerganov interprets the GGML and GGUF formats.

**Artificial neurons** are software modules, called nodes, and artificial neural networks are software programs or algorithms that, at their core, use computing systems to solve mathematical calculations.

.. note::

  Task 4.1: Write a list over concepts that you do not understand. Go in pairs, and discuss the concepts you want to elaborate on. Use google, UiO GPT or an encyclopedia from the library.


.. todo:: 
  Todo 4.1: Vi må legge inn oppgaver der det passer. Det er bedre å erfare enn å lese.

.. todo:: 
  Todo 4.2: Indikere minutter på alle oppgavene. Hvor lang tid tar hver oppgave?
