
In this project, We use Sphinx to formulate `our ideas: <https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html>`_.

Run large language models through Educloud UiO
====================================
.. image:: fox.png

.. note::

   This project is under active development.

In this documentation, you will learn how to set up your an AI process at the UiO Nvidia Cluster. The documentation belongs to a course held as a part of Digital Scholarship Days 2025. The course is for employees at the University of Oslo. If you are in our interest group, you may `sign up here <https://www.ub.uio.no/english/courses-events/events/dsc/2025/digital-scholarship-days/01-run%20large%20language%20models%20through%20Educloud%20UiO>`_. AIs from Huggingface run on a Transformer architecture. The method we are going to use, Jupyter Lab is an effective way of showing what goes on behind the interface of the AI. You will learn how the language model is built, how the parameters are set, and what the output is like. We hope this will give you insight into how the AI of our times work.


Contents
--------

.. toctree::
   :maxdepth: 2

   00_preparations
   01_ai_board
   02_login
   03_pasting code
   04_something
   05_noko
   06_etwas
   07_jotain
   08_disk_quota
   09_elastic_search

Indices and tables
==================

* :ref:`genindex`
* :ref:`search`
