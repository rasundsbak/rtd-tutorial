
In this project, We use Sphinx to formulate `our ideas: <https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html>`_.

Run large language models through Educloud UiO
==============================================

.. image:: fox.png

.. note::

   This project is under active development.

In this documentation, you will learn how to set up your an AI process at the UiO Nvidia Cluster. The documentation belongs to a course held as a part of Digital Scholarship Days 2025. The course is for employees at the University of Oslo. If you are in our interest group, you may `sign up here <https://www.ub.uio.no/english/courses-events/events/dsc/2025/digital-scholarship-days/01-run%20large%20language%20models%20through%20Educloud%20UiO>`_. AIs from Huggingface run on a Transformer architecture. The method we are going to use, Jupyter Lab is an effective way of showing what goes on behind the interface of the AI. You will learn how the language model is built, how the parameters are set, and what the output is like. We hope this will give you insight into how the AI of our times work.

Contents
--------

.. toctree::
   :maxdepth: 2

   00_preparations
   01_this_is_a_test
   02_hugging_face
   03_get_overview
   04_log_in_to
   05_what_is_a_cluster
   06_log_on_to
   07_disk_quota
   08_images

Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
