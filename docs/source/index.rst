In this project, We use `Sphinx <https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html>`_ to formulate our ideas.

Run large language models through Educloud UiO
=============================================

.. image:: fox.png

In this documentation, you will learn how to set up an AI process at the UiO Nvidia Cluster. The documentation belongs to a course held as a part of Digital Scholarship Days 2025. The course is for employees at the University of Oslo. If you are in the interest group, you may `sign up here <https://www.ub.uio.no/english/courses-events/events/dsc/2025/digital-scholarship-days/01-run%20large%20language%20models%20through%20Educloud%20UiO>`_. AIs from Huggingface run on a Transformer architecture. The interactive development environment we are going to use, Jupyter Lab, is an effective way of showing what goes on behind the interface of the AI. You will learn how the functionality of the various language models are put together. You will also learn to set parameters, and how they affect the output. This will give some insight into how the AI of our times work.

.. todo:: 
   Todo 0.1: Språkvask engelsk: spør noen som er flytende i engelsk om hjelp.


.. todo:: 
   Todo 0.2: Legg emneord på alle kapitlene der det mangler.

Learning objectives
-------------------
- Learn how large language models (LLMs) are made
- learn how to use UiOs infrastructure for computational power to use various open LLMs
- Learn how to create effective promts and adjust relevant parameters
- Connect the model to your own data in the form of PDFs og text data.
- Be fluent in how to set up your own model in Jupyter Lab, so that you may use the process independently for interaction with open LLMs

Contents
--------

.. toctree::
   :maxdepth: 2
   :caption: Table of Contents
   :titlesonly:

   00_run_llms
   01_preparations
   02_downloading_packages
   03_ai_board
   04_hello_world
   05_login
   06_prompting
   07_pirat
   08_parameters
   09_pegasus
   10_valami
   11_juoga
   30_todo

Indices and tables
==================

* :ref:`genindex`
* :ref:`search`

